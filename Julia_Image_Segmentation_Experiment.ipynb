{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa838846de794144a4d1b680a361a0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Yes",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1e4ddb3bbe654d4bb72fb49d3adcae46",
            "style": "IPY_MODEL_8626288b585f480db8f63ddf09768edb",
            "tooltip": ""
          }
        },
        "1e4ddb3bbe654d4bb72fb49d3adcae46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8626288b585f480db8f63ddf09768edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "77194c8348984ae5a5d4657e2de886a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Continue",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5019551632ac4c24844254d5aaa637ec",
            "style": "IPY_MODEL_f0a6ba4b17c145d4be20df33256e9d96",
            "tooltip": ""
          }
        },
        "5019551632ac4c24844254d5aaa637ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a6ba4b17c145d4be20df33256e9d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "93afd459f2f44b46b182804d80609ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Retake",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9a67ef8380064787a26021f69efa17ab",
            "style": "IPY_MODEL_6fbd6ccfb9624887b298398e246f20e0",
            "tooltip": ""
          }
        },
        "9a67ef8380064787a26021f69efa17ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fbd6ccfb9624887b298398e246f20e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "83313135d9fc46f6b53217cbcda266d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Try Again",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_113a18a37b9849f5bedbf344e6f8495c",
            "style": "IPY_MODEL_5947acf6407249afa540aba5b5be7c9b",
            "tooltip": ""
          }
        },
        "113a18a37b9849f5bedbf344e6f8495c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5947acf6407249afa540aba5b5be7c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Final Project Code\n",
        "\n",
        "This is the final project notebook file for COMSC 341-CV Computer Vision.\n",
        "\n",
        "*Project Title*:\n",
        "Leaf Doctors\n",
        "\n",
        "*Project Description*:\n",
        "Our project allows user to capture their leaf's picture and know if the leaf is healthy or unhealthy. Our project only segments the leaf from the image and uses a ML model to decides it's health.\n",
        "\n",
        "*Team Name*:\n",
        "ClimateTeam\n",
        "\n",
        "*Group Members*:\n",
        "Julia Diep Ho, Sulagna Saha, Autumn Nguyen\n",
        "\n",
        "*Credit*: See below for a list of reference code our group uses.\n",
        "Sobel Edge Detection code from COMSC-341CV Fall 2023 by Yu-Hsun Su\n",
        "\n",
        "https://www.frontiersin.org/articles/10.3389/fpls.2016.01419/full\n",
        "\n",
        "https://github.com/digitalepidemiologylab/plantvillage_deeplearning_paper_analysis for Image Segmentation Code\n",
        "\n",
        "Data Used: https://data.mendeley.com/datasets/t6j2h22jpx/1\n",
        " ver. 111223"
      ],
      "metadata": {
        "id": "74ngKbBhhTM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Segmenting Simple Picture with Leaves Only using Sobel Edge Detection\n",
        "\n",
        "Test Dataset: https://www.tensorflow.org/datasets/catalog/plant_leaves"
      ],
      "metadata": {
        "id": "SZ1G651VF1IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os.path\n",
        "from time import time\n",
        "import types\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "v5te0fovI1C0"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import PIL.Image as pil\n",
        "import scipy.signal as sps\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import map_coordinates\n",
        "\n",
        "def compute_gradients(img):\n",
        "\n",
        "  Ix=np.zeros_like(img)\n",
        "  Iy=np.zeros_like(img)\n",
        "\n",
        "  # extract the size of the input image\n",
        "  h, w, b = img.shape\n",
        "\n",
        "  # compute gradients using finite differences\n",
        "  for y in range(1, h - 1):\n",
        "      for x in range(1, w - 1):\n",
        "        # compute x-gradient (Ix)\n",
        "        Ix[y, x] = (img[y, x + 1] - img[y, x - 1]) / 2.0\n",
        "\n",
        "        # Compute y-gradient (Iy)\n",
        "        Iy[y, x] = (img[y + 1, x] - img[y - 1, x]) / 2.0\n",
        "\n",
        "  return Ix, Iy\n",
        "\n",
        "def compute_sobel(img):\n",
        "\n",
        "  Sx=np.zeros_like(img)\n",
        "  Sy=np.zeros_like(img)\n",
        "\n",
        "  # extract dimensions of the input image\n",
        "  h, w = img.shape[:2]\n",
        "\n",
        "  # Sobel kernels\n",
        "  kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "  kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "\n",
        "  # loop through the pixels that are in the inner side of the image\n",
        "  for y in range(1, h - 1):\n",
        "      for x in range(1, w - 1):\n",
        "          # x-gradient (Sx) using the Sobel kernel\n",
        "          Sx[y, x] = np.sum(img[y - 1:y + 2, x - 1:x + 2] * kernel_x)\n",
        "\n",
        "          # y-gradient (Sy) using the Sobel kernel\n",
        "          Sy[y, x] = np.sum(img[y - 1:y + 2, x - 1:x + 2] * kernel_y)\n",
        "\n",
        "  return Sx, Sy\n",
        "\n",
        "def image_open(filename):\n",
        "  \"\"\"\n",
        "  Returns a numpy float image with values in the range (0,1)\n",
        "  \"\"\"\n",
        "  pil_im = pil.open(filename)\n",
        "  im_np = np.array(pil_im).astype(np.float32)\n",
        "  im_np /= 255.0\n",
        "  return im_np\n",
        "\n",
        "def image_save(im_np, filename):\n",
        "  \"\"\"\n",
        "  Saves a numpy float image to file\n",
        "  \"\"\"\n",
        "  if (len(im_np.shape)==2):\n",
        "    im_np = np.expand_dims(im_np, 2)\n",
        "  if (im_np.shape[2]==1):\n",
        "    im_np= np.repeat(im_np, 3, axis=2)\n",
        "  im_np = np.maximum(0.0, np.minimum(im_np, 1.0))\n",
        "  pil_im = pil.fromarray((im_np*255).astype(np.uint8))\n",
        "  pil_im.save(filename)\n",
        "\n",
        "def plot_many_images(*imgs):\n",
        "  \"\"\"\n",
        "  Plot two images and return axis handles\n",
        "  \"\"\"\n",
        "  count = len(imgs)\n",
        "  axs = []\n",
        "  for i in range(count):\n",
        "    axs.append(plt.subplot(1,count,i+1))\n",
        "    plt.imshow(imgs[i])\n",
        "    plt.axis('off')\n",
        "  return axs\n",
        "\n",
        "def normalise_01(im):\n",
        "  \"\"\"\n",
        "  Normalise image to the range (0,1)\n",
        "  \"\"\"\n",
        "  mx = im.max()\n",
        "  mn = im.min()\n",
        "  den = mx-mn\n",
        "  small_val = 1e-9\n",
        "  if (den < small_val):\n",
        "    print('image normalise_01 -- divisor is very small')\n",
        "    den = small_val\n",
        "  return (im-mn)/den\n",
        "\n",
        "def grey_to_rgb(img):\n",
        "  \"\"\"\n",
        "  Convert greyscale to rgb image\n",
        "  \"\"\"\n",
        "  if (len(img.shape)==2):\n",
        "    img = np.expand_dims(img, 2)\n",
        "\n",
        "  img3 = np.repeat(img, 3, 2)\n",
        "  return img3\n",
        "\n",
        "def disc_mask(l):\n",
        "  \"\"\"\n",
        "  Create a binary cirular mask of radius l\n",
        "  \"\"\"\n",
        "  sz = 2 * l + 1\n",
        "  m = np.zeros((sz,sz))\n",
        "  x = np.linspace(-l,l,2*l+1)/l\n",
        "  x = np.expand_dims(x, 1)\n",
        "  m = x**2\n",
        "  m = m + m.T\n",
        "  m = m<1\n",
        "  m = np.expand_dims(m, 2)\n",
        "  return m\n",
        "\n",
        "# allow accessing these functions by im_util.*\n",
        "im_util=types.SimpleNamespace()\n",
        "im_util.compute_gradients=compute_gradients\n",
        "im_util.compute_sobel=compute_sobel\n",
        "im_util.image_open=image_open\n",
        "im_util.image_save=image_save\n",
        "im_util.plot_many_images=plot_many_images\n",
        "im_util.normalise_01=normalise_01\n",
        "im_util.grey_to_rgb=grey_to_rgb\n",
        "im_util.disc_mask=disc_mask"
      ],
      "metadata": {
        "id": "LashZe9CHFFC"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting Leaf from A More Complex Picture"
      ],
      "metadata": {
        "id": "wk6_WzOTQqht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Helper functions\n",
        "\"\"\"\n",
        "# Function to compute sobel gray\n",
        "def compute_sobel_gray(image_filename):\n",
        "  im = im_util.image_open(image_filename)\n",
        "  # Resize the image\n",
        "  im = cv2.resize(im, dsize=(600, 400), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "  # Compute Sobel for each color channel\n",
        "  Sx_out = np.zeros_like(im)\n",
        "  Sy_out = np.zeros_like(im)\n",
        "\n",
        "  for channel in range(3):\n",
        "    channel_im = im[:, :, channel]\n",
        "    Sx = im_util.compute_sobel(channel_im)[0]\n",
        "    Sy = im_util.compute_sobel(channel_im)[1]\n",
        "    Sx_out[:, :, channel] = Sx\n",
        "    Sy_out[:, :, channel] = Sy\n",
        "\n",
        "  sobel_magnitude = np.sqrt(Sx_out**2 + Sy_out**2)\n",
        "  # Convert Sobel magnitude to grayscale\n",
        "  sobel_gray = cv2.cvtColor(sobel_magnitude, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  return im, sobel_gray\n",
        "\n",
        "def find_edges(im, sobel_gray):\n",
        "  # Set a threshold to extract brighter pixels\n",
        "  threshold_value = 0.5\n",
        "\n",
        "  # Mask with edge pixels marked 1\n",
        "  edge_mask = np.zeros((400,600))\n",
        "\n",
        "  # H, W = sobel_gray.shape\n",
        "  for h in range(400):\n",
        "    for w in range(600):\n",
        "      if sobel_gray[h][w] > threshold_value:\n",
        "        edge_mask[h][w] = 1.0\n",
        "\n",
        "  # Display the result\n",
        "  return edge_mask\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function to segment leaf and draw edges\n",
        "\"\"\"\n",
        "def edge_detection(image_filename):\n",
        "  im, sobel_gray = compute_sobel_gray(image_filename)\n",
        "  edges = find_edges(im, sobel_gray)"
      ],
      "metadata": {
        "id": "Z5dfqigJRnGh"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmenting Leaf"
      ],
      "metadata": {
        "id": "EqFUaS8oXVp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "# The steps which are suggested in the paper\n",
        "# Improve/standardise the image\n",
        "# Detect the color characteristics of the background\n",
        "# Reconstruct a better image\n",
        "# Create a collection of masks based on various characteristics of the image\n",
        "# Process the masks and combine them in a final mask\n",
        "# Use the final mask to make the background black\n",
        "\n",
        "def segment(image_filename):\n",
        "\n",
        "  # Detect edges in the image\n",
        "  edges = edge_detection(image_filename)\n",
        "\n",
        "  image = im_util.image_open(image_filename)\n",
        "  # Convert the image to Lab color space\n",
        "  image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
        "\n",
        "  # Split into L, a, b channels\n",
        "  l, a, b = cv2.split(image_lab)\n",
        "\n",
        "  # Apply a Gaussian blur to the L, a, and b channels\n",
        "  l_blurred = cv2.GaussianBlur(l, (5, 5), 0)\n",
        "  a_blurred = cv2.GaussianBlur(a, (5, 5), 0)\n",
        "  b_blurred = cv2.GaussianBlur(b, (5, 5), 0)\n",
        "\n",
        "  # Calculate the median color of the image edges\n",
        "  median_a = np.median(a_blurred[edges != 0])\n",
        "  median_b = np.median(b_blurred[edges != 0])\n",
        "\n",
        "  # Shift the a and b channels so that the background becomes gray\n",
        "  a_shifted = a_blurred - (median_a - 128)\n",
        "  b_shifted = b_blurred - (median_b - 128)\n",
        "\n",
        "  # Ensure the shifted channels have the same size and type as the L channel\n",
        "  a_shifted = cv2.resize(a_shifted, (l_blurred.shape[1], l_blurred.shape[0]))\n",
        "  b_shifted = cv2.resize(b_shifted, (l_blurred.shape[1], l_blurred.shape[0]))\n",
        "  a_shifted = a_shifted.astype(l_blurred.dtype)\n",
        "  b_shifted = b_shifted.astype(l_blurred.dtype)\n",
        "\n",
        "  # Reconstruct the Lab image\n",
        "  image_lab_shifted = cv2.merge((l_blurred, a_shifted, b_shifted))\n",
        "\n",
        "  # Convert back to RGB to apply the mask\n",
        "  image_rgb_shifted = cv2.cvtColor(image_lab_shifted, cv2.COLOR_Lab2RGB)\n",
        "\n",
        "  # Threshold the a and b channels to create the masks\n",
        "  _, color_mask = cv2.threshold(a_shifted, 128, 255, cv2.THRESH_BINARY_INV)\n",
        "  _, shadow_mask = cv2.threshold(b_shifted, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  # Combine the color and shadow masks\n",
        "  combined_mask = cv2.bitwise_and(color_mask, shadow_mask)\n",
        "\n",
        "  # Process the mask to remove noise and artifacts\n",
        "  kernel = np.ones((5, 5), np.uint8)\n",
        "  processed_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
        "  processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  # Fill in the holes to complete the mask\n",
        "  filled_mask = ndi.binary_fill_holes(processed_mask).astype(np.uint8) * 255\n",
        "\n",
        "  # Blur the mask slightly\n",
        "  final_mask = cv2.GaussianBlur(filled_mask, (5, 5), 0)\n",
        "\n",
        "  # remove all connected components\n",
        "  # Find connected components in the mask\n",
        "  num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(final_mask, connectivity=8)\n",
        "  image_center = (labels.shape[1] // 2, labels.shape[0] // 2)\n",
        "\n",
        "  # each component has a score based on how big they are and how far from the center they are\n",
        "  # might not work best for all the images\n",
        "  scores = []\n",
        "\n",
        "  # Calculate scores for each component (excluding the background)\n",
        "  for i in range(1, num_labels):\n",
        "      # Calculate the Euclidean distance from the centroid to the image center\n",
        "      distance = np.sqrt((centroids[i, 0] - image_center[0]) ** 2 + (centroids[i, 1] - image_center[1]) ** 2)\n",
        "      # Normalize the distance based on the maximum possible distance (diagonal of the image)\n",
        "      max_distance = np.sqrt(image_center[0]**2 + image_center[1]**2)\n",
        "      normalized_distance = distance / max_distance\n",
        "\n",
        "      # Get the area of the blob\n",
        "      area = stats[i, cv2.CC_STAT_AREA]\n",
        "\n",
        "      # a score as the area divided by the normalized distance\n",
        "      # This gives higher scores to larger blobs that are closer to the center\n",
        "      # You can adjust the weight of the distance vs the area by changing the exponent\n",
        "      score = area / (normalized_distance + 1e-5)  # Add a small value to avoid division by zero\n",
        "\n",
        "      scores.append((score, i))\n",
        "\n",
        "  # Find the label with the highest score\n",
        "  _, best_label = max(scores, key=lambda x: x[0])\n",
        "\n",
        "  # Create a mask with only the best blob\n",
        "  best_blob_mask = np.zeros_like(labels, dtype=np.uint8)\n",
        "  best_blob_mask[labels == best_label] = 255\n",
        "\n",
        "\n",
        "  # Apply the mask to the original image to get the original color\n",
        "  final_image = cv2.bitwise_and(image, image, mask=best_blob_mask)\n",
        "\n",
        "  # Save the image\n",
        "  image_save(final_image, 'output.jpg')\n",
        "\n",
        "  # # Display result\n",
        "  im_util.plot_many_images(image, best_blob_mask, final_image)\n",
        "\n",
        "  return final_image"
      ],
      "metadata": {
        "id": "d9mUKhxaXYAs"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Webcam Try-Out"
      ],
      "metadata": {
        "id": "CxqSKllGLADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "3avpAvMfLCF8"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "7VTlxwDlLFC6"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename"
      ],
      "metadata": {
        "id": "ScohEU5OLHz8"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GUI"
      ],
      "metadata": {
        "id": "q0n6kvePfiQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import widgets\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "6VgZPWLtisYf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLS0zaGkb0ZC",
        "outputId": "1face3f7-d51a-47f8-9029-4ea2d8944629"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import ML model\n",
        "from tensorflow.keras.models import load_model\n",
        "cnn_1 = load_model('/content/drive/MyDrive/Fall 2023/COMSC 341/ML models/cnn_1.h5')"
      ],
      "metadata": {
        "id": "7-8w9G1DcP2W"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, clear_output\n",
        "\n",
        "# State variable\n",
        "capturing_phase = False\n",
        "\n",
        "def capture():\n",
        "    global capturing_phase\n",
        "    print(\"\\nHold your leaf as close to the webcam and position it closest to the center as you can.\")\n",
        "    print(\"Make sure that you can see the whole leaf in the frame.\")\n",
        "    print(\"\\nWhen you're ready, choose [Capture]!\")\n",
        "    filename = take_photo('photo.jpg')\n",
        "\n",
        "    # Show the image which was just taken.\n",
        "    display(Image(filename))\n",
        "    capturing_phase = False\n",
        "\n",
        "def on_continue_button_click(b):\n",
        "    print(\"\\nSegmentation in process.. Please wait.\")\n",
        "    output_img = segment('/content/photo.jpg')\n",
        "\n",
        "    # resize the image\n",
        "    output_img = cv2.resize(output_img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "    # call the model\n",
        "    output = cnn_1.predict(np.expand_dims(output_img/255, 0))\n",
        "    output = float('%.3f'%(output))\n",
        "\n",
        "    # displaying final message\n",
        "    if output > 0.5:\n",
        "      print(f\"\\nWe are {'%.3f'%(output * 100)}% sure that your leaf is Unhealthy.\")\n",
        "    else:\n",
        "      print(f\"\\nWe are {'%.3f'%(output * 100)}% sure that your leaf is Healthy.\")\n",
        "    display_try_again_button()\n",
        "\n",
        "def on_try_again_button_click(b):\n",
        "    # Clear previous output and reset capturing_phase\n",
        "    clear_output(wait=True)\n",
        "    global capturing_phase\n",
        "    capturing_phase = False\n",
        "\n",
        "    # Display the welcome messages and \"Yes\" button again\n",
        "    display_welcome()\n",
        "    print(\"\\nAre you ready to start?\")\n",
        "    display(yes_button)\n",
        "\n",
        "def display_try_again_button():\n",
        "    try_again_button = widgets.Button(description='Try Again')\n",
        "\n",
        "    display(try_again_button)\n",
        "\n",
        "    try_again_button.on_click(on_try_again_button_click)\n",
        "\n",
        "# Function to handle \"Yes\" button click event\n",
        "def on_yes_button_click(b):\n",
        "    global capturing_phase\n",
        "    try:\n",
        "        # Clear output before displaying messages\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if not capturing_phase:\n",
        "            capturing_phase = True\n",
        "            capture()\n",
        "\n",
        "            # continue button\n",
        "            continue_button = widgets.Button(description='Continue')\n",
        "            display(continue_button)\n",
        "            continue_button.on_click(on_continue_button_click)\n",
        "\n",
        "            # retake button\n",
        "            retake_button = widgets.Button(description='Retake')\n",
        "            display(retake_button)\n",
        "            retake_button.on_click(lambda b: on_yes_button_click(b))\n",
        "\n",
        "        else:\n",
        "            # User is in the capturing phase, not making a decision\n",
        "            print(\"\\nYou are still in the capturing phase. Capture a photo first.\")\n",
        "    except Exception as err:\n",
        "        # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "        # grant the page permission to access it.\n",
        "        print(str(err))\n",
        "\n",
        "# Welcome messages\n",
        "def display_welcome():\n",
        "  print(\"WELCOME TO LEAF DOCTORS 🌿👩‍⚕️!\")\n",
        "  print(\"\\nLeafJAR is developed by LeafTeam, a CV-341 project group. Our goal is to help you take better care of your first-year plants at MHC.\")\n",
        "  print(\"There is a myth that if you can keep your first-year plants healthy during your time here, you'll become a millionaire.\")\n",
        "  print(\"This is the first step that can help it to be more likely to happen!\")\n",
        "\n",
        "  print(\"\\nWondering if a leaf from your plant is healthy or not? Have it ready and we can tell you!\")\n",
        "\n",
        "# Starting widget\n",
        "display_welcome()\n",
        "print(\"\\nAre you ready to start?\")\n",
        "yes_button = widgets.Button(description='Yes')\n",
        "yes_button.on_click(on_yes_button_click)\n",
        "\n",
        "# Display the \"Yes\" button\n",
        "display(yes_button)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "fa838846de794144a4d1b680a361a0d8",
            "1e4ddb3bbe654d4bb72fb49d3adcae46",
            "8626288b585f480db8f63ddf09768edb",
            "77194c8348984ae5a5d4657e2de886a5",
            "5019551632ac4c24844254d5aaa637ec",
            "f0a6ba4b17c145d4be20df33256e9d96",
            "93afd459f2f44b46b182804d80609ad7",
            "9a67ef8380064787a26021f69efa17ab",
            "6fbd6ccfb9624887b298398e246f20e0",
            "83313135d9fc46f6b53217cbcda266d4",
            "113a18a37b9849f5bedbf344e6f8495c",
            "5947acf6407249afa540aba5b5be7c9b"
          ]
        },
        "id": "TYbcX0QimpXl",
        "outputId": "14f18c83-66a5-44ed-9489-54104fe1ed76"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WELCOME TO LEAF DOCTORS 🌿👩‍⚕️!\n",
            "\n",
            "LeafJAR is developed by LeafTeam, a CV-341 project group. Our goal is to help you take better care of your first-year plants at MHC.\n",
            "There is a myth that if you can keep your first-year plants healthy during your time here, you'll become a millionaire.\n",
            "This is the first step that can help it to be more likely to happen!\n",
            "\n",
            "Wondering if a leaf from your plant is healthy or not? Have it ready and we can tell you!\n",
            "\n",
            "Are you ready to start?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Yes', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa838846de794144a4d1b680a361a0d8"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}